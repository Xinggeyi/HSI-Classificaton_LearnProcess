{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# mobile V2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, Sequential\n",
    "# from model import MobileNetV2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(ch, divisor=8, min_ch=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_ch is None:\n",
    "        min_ch = divisor\n",
    "    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_ch < 0.9 * ch:\n",
    "        new_ch += divisor\n",
    "    return new_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size=3, stride=1, **kwargs):\n",
    "        super(ConvBNReLU, self).__init__(**kwargs)\n",
    "        self.conv = layers.Conv2D(filters=out_channel, kernel_size=kernel_size,\n",
    "                                  strides=stride, padding='SAME', use_bias=False, name='Conv2d')  # 迁移学习中调用权重信息用到 name\n",
    "        self.bn = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='BatchNorm')\n",
    "        # ReLU6\n",
    "        self.activation = layers.ReLU(max_value=6.0)\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(layers.Layer):\n",
    "    # expand_ratio 控制特征矩阵的深度\n",
    "    def __init__(self, in_channel, out_channel, stride, expand_ratio, **kwargs):\n",
    "        super(InvertedResidual, self).__init__(**kwargs)\n",
    "        self.hidden_channel = in_channel * expand_ratio\n",
    "        self.use_shortcut = stride == 1 and in_channel == out_channel\n",
    "\n",
    "        layer_list = []\n",
    "        if expand_ratio != 1:\n",
    "            # 1x1 pointwise conv\n",
    "            layer_list.append(ConvBNReLU(out_channel=self.hidden_channel, kernel_size=1, name='expand'))\n",
    "\n",
    "        ## extend TODO\n",
    "        layer_list.extend([\n",
    "            # 3x3 depthwise conv\n",
    "            layers.DepthwiseConv2D(kernel_size=3, padding='SAME', strides=stride,\n",
    "                                   use_bias=False, name='depthwise'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='depthwise/BatchNorm'),\n",
    "            layers.ReLU(max_value=6.0),\n",
    "            # 1x1 pointwise conv(linear)\n",
    "            layers.Conv2D(filters=out_channel, kernel_size=1, strides=1,\n",
    "                          padding='SAME', use_bias=False, name='project'),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='project/BatchNorm')\n",
    "        ])\n",
    "        # 主分支的输出\n",
    "        self.main_branch = Sequential(layer_list, name='expanded_conv')\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if self.use_shortcut:\n",
    "            return inputs + self.main_branch(inputs)\n",
    "        else:\n",
    "            return self.main_branch(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型框架\n",
    "# alpha=1.0 调节卷积核个数，round_nearest 调整卷积个数为 8 的倍数\n",
    "def MobileNetV2(im_height=224, im_width=224, im_channel=3, num_classes=1000, alpha=1.0, round_nearest=8):\n",
    "    block = InvertedResidual\n",
    "    input_channel = _make_divisible(32 * alpha, round_nearest)\n",
    "    last_channel = _make_divisible(1280 * alpha, round_nearest)\n",
    "    \n",
    "    # t 扩展因子， c 输入特征的深度， n bottleneck 的重复次数\n",
    "    inverted_residual_setting = [\n",
    "        # t, c, n, s\n",
    "        [1, 16, 1, 1],\n",
    "        [6, 24, 2, 2],\n",
    "        [6, 32, 3, 2],\n",
    "        [6, 64, 4, 2],\n",
    "        [6, 96, 3, 1],\n",
    "        [6, 160, 3, 2],\n",
    "        [6, 320, 1, 1],\n",
    "    ]\n",
    "\n",
    "    input_image = layers.Input(shape=(im_height, im_width, im_channel), dtype='float32')\n",
    "    # conv1\n",
    "    x = ConvBNReLU(input_channel, stride=2, name='Conv')(input_image)   # 此处默认卷积核大小为 3\n",
    "    # building inverted residual residual blockes\n",
    "    for t, c, n, s in inverted_residual_setting:\n",
    "        output_channel = _make_divisible(c * alpha, round_nearest)\n",
    "        for i in range(n):\n",
    "            stride = s if i == 0 else 1\n",
    "            x = block(x.shape[-1], output_channel, stride, expand_ratio=t)(x)\n",
    "    # building last several layers\n",
    "    x = ConvBNReLU(last_channel, kernel_size=1, name='Conv_1')(x)\n",
    "\n",
    "    # building classifier\n",
    "    x = layers.GlobalAveragePooling2D()(x)  # pool + flatten\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(num_classes, name='Logits')(x)\n",
    "\n",
    "    model = Model(inputs=input_image, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "E:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\data.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\data_label.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\test.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\test_label.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\train.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\train_label.npy\n"
     ]
    }
   ],
   "source": [
    "data_dir= \"E:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\"\n",
    "data_root = glob.glob(data_dir + '/*')\n",
    "for name in glob.glob(data_dir + '/*'):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((3200, 9, 9, 204), (3200,), (50929, 9, 9, 204), (50929,))"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "train = np.load(data_root[4])\n",
    "train_label = np.load(data_root[5])\n",
    "test = np.load(data_root[2])\n",
    "test_label = np.load(data_root[3])\n",
    "train.shape, train_label.shape, test.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSZ = 64\n",
    "batch_size = 64\n",
    "class_num = 16\n",
    "im_height = 9\n",
    "im_width = 9\n",
    "epochs = 10\n",
    "im_channel = train.shape[3]\n",
    "train_num = train.shape[0]\n",
    "val_num = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据可用的CPU动态设置并行调用的数量， 应用于 num_parallel_calls\n",
    "\n",
    "train_label = tf.keras.utils.to_categorical(train_label)\n",
    "test_label = tf.keras.utils.to_categorical(test_label)\n",
    "\n",
    "# 根据可用的CPU动态设置并行调用的数量， 应用于 num_parallel_calls\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# load train dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train, train_label))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_num).repeat().batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=train_num).batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "\n",
    "# load test dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((test, test_label))\n",
    "val_dataset = val_dataset.repeat().batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "# val_dataset = val_dataset.batch(BATCHSZ).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 9, 9, 204), (None, 16)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 9, 9, 204), (None, 16)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "train_dataset, val_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 9, 9, 204)]       0         \n_________________________________________________________________\nConv (ConvBNReLU)            (None, 5, 5, 32)          58880     \n_________________________________________________________________\ninverted_residual_51 (Invert (None, 5, 5, 16)          992       \n_________________________________________________________________\ninverted_residual_52 (Invert (None, 3, 3, 24)          5568      \n_________________________________________________________________\ninverted_residual_53 (Invert (None, 3, 3, 24)          9456      \n_________________________________________________________________\ninverted_residual_54 (Invert (None, 2, 2, 32)          10640     \n_________________________________________________________________\ninverted_residual_55 (Invert (None, 2, 2, 32)          15680     \n_________________________________________________________________\ninverted_residual_56 (Invert (None, 2, 2, 32)          15680     \n_________________________________________________________________\ninverted_residual_57 (Invert (None, 1, 1, 64)          21952     \n_________________________________________________________________\ninverted_residual_58 (Invert (None, 1, 1, 64)          55936     \n_________________________________________________________________\ninverted_residual_59 (Invert (None, 1, 1, 64)          55936     \n_________________________________________________________________\ninverted_residual_60 (Invert (None, 1, 1, 64)          55936     \n_________________________________________________________________\ninverted_residual_61 (Invert (None, 1, 1, 96)          68352     \n_________________________________________________________________\ninverted_residual_62 (Invert (None, 1, 1, 96)          120768    \n_________________________________________________________________\ninverted_residual_63 (Invert (None, 1, 1, 96)          120768    \n_________________________________________________________________\ninverted_residual_64 (Invert (None, 1, 1, 160)         157888    \n_________________________________________________________________\ninverted_residual_65 (Invert (None, 1, 1, 160)         324160    \n_________________________________________________________________\ninverted_residual_66 (Invert (None, 1, 1, 160)         324160    \n_________________________________________________________________\ninverted_residual_67 (Invert (None, 1, 1, 320)         478400    \n_________________________________________________________________\nConv_1 (ConvBNReLU)          (None, 1, 1, 1280)        414720    \n_________________________________________________________________\nglobal_average_pooling2d_3 ( (None, 1280)              0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1280)              0         \n_________________________________________________________________\nLogits (Dense)               (None, 16)                20496     \n=================================================================\nTotal params: 2,336,368\nTrainable params: 2,302,256\nNon-trainable params: 34,112\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create direction for saving weights\n",
    "if not os.path.exists(\"save_weights\"):\n",
    "    os.makedirs(\"save_weights\")\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "model = MobileNetV2(im_height=im_height, im_width=im_width, im_channel=im_channel, num_classes=class_num, alpha=1.0, round_nearest=8)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras low level api for training\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model(images, training=True)\n",
    "        loss = loss_object(labels, output)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    output = model(images, training=False)\n",
    "    t_loss = loss_object(labels, output)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.68980380000005\n",
      "Epoch 1, Loss: 2.066819190979004, Accuracy: 34.34375, Test Loss: 3.0094127655029297, Test Accuracy: 3.4905660152435303\n",
      "0.677453200000059\n",
      "Epoch 2, Loss: 1.0890570878982544, Accuracy: 62.343753814697266, Test Loss: 1.440706729888916, Test Accuracy: 48.724449157714844\n",
      "0.679537200000027\n",
      "Epoch 3, Loss: 0.74652099609375, Accuracy: 73.5625, Test Loss: 0.9158334136009216, Test Accuracy: 65.71934509277344\n",
      "0.6854324999999335\n",
      "Epoch 4, Loss: 0.6209841370582581, Accuracy: 77.96875, Test Loss: 0.5073484182357788, Test Accuracy: 74.6128158569336\n",
      "0.7016564000000471\n",
      "Epoch 5, Loss: 0.4849494993686676, Accuracy: 82.78125, Test Loss: 0.43151625990867615, Test Accuracy: 82.22877502441406\n",
      "0.7017526999999291\n",
      "Epoch 6, Loss: 0.5203126072883606, Accuracy: 82.21875, Test Loss: 0.7346500754356384, Test Accuracy: 65.04913330078125\n",
      "0.6898727000000235\n",
      "Epoch 7, Loss: 0.40045440196990967, Accuracy: 85.0625, Test Loss: 0.4427463114261627, Test Accuracy: 82.78498840332031\n",
      "0.7090054000000237\n",
      "Epoch 8, Loss: 0.31393182277679443, Accuracy: 88.71875, Test Loss: 0.3716389536857605, Test Accuracy: 85.87460327148438\n",
      "0.6987672999999859\n",
      "Epoch 9, Loss: 0.3235868215560913, Accuracy: 87.78125, Test Loss: 0.9328542351722717, Test Accuracy: 71.3128890991211\n",
      "0.6865347000000384\n",
      "Epoch 10, Loss: 0.2919176518917084, Accuracy: 89.03125, Test Loss: 0.31801557540893555, Test Accuracy: 86.1517333984375\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = float('inf')\n",
    "train_step_num = train_num // batch_size\n",
    "val_step_num = val_num // batch_size\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss.reset_states()        # clear history info\n",
    "    train_accuracy.reset_states()    # clear history info\n",
    "    test_loss.reset_states()         # clear history info\n",
    "    test_accuracy.reset_states()     # clear history info\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    for index, (images, labels) in enumerate(train_dataset):\n",
    "        train_step(images, labels)\n",
    "        if index+1 == train_step_num:\n",
    "            break\n",
    "    print(time.perf_counter()-t1)\n",
    "\n",
    "    for index, (images, labels) in enumerate(val_dataset):\n",
    "        test_step(images, labels)\n",
    "        if index+1 == val_step_num:\n",
    "            break\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch,\n",
    "                            train_loss.result(),\n",
    "                            train_accuracy.result() * 100,\n",
    "                            test_loss.result(),\n",
    "                            test_accuracy.result() * 100))\n",
    "    if test_loss.result() < best_test_loss:\n",
    "        model.save_weights(\"./save_weights/myMobileNet.ckpt\".format(epoch), save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}