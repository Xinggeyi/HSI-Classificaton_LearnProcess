{
 "cells": [
  {
   "source": [
    "# 一种划分patch的策略\n",
    "- 用5*5的pathch中最多的个点的像素值取代替一个点像素值，这样会丢失数据的信息"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensorflow中添加每一层的命令都是大写的\n",
    "- conv kernel 的数量是以 2 的 n 次方的形式递增的\n",
    "- 通过 pooling 池化层，相同大小的卷积核覆盖的区域将变大，这是pooling的重要意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'salinas_corrected'])\ndict_keys(['__header__', '__version__', '__globals__', 'salinas_gt'])\n"
     ]
    }
   ],
   "source": [
    "#  load the Indian pines dataset which is the .mat format\n",
    "def loadData():\n",
    "    data_path = os.path.join(r'E:\\Eric_HSI\\hyperspectral_datasets')\n",
    "    data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))\n",
    "    labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))\n",
    "    return data, labels\n",
    "\n",
    "X, y = loadData()\n",
    "\n",
    "# 打印keys\n",
    "print(X.keys())\n",
    "print(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将dict to ndarray\n",
    "def dict_to_array(X, y):\n",
    "    data = X[list(X)[-1]]\n",
    "    labels = y[list(y)[-1]]\n",
    "    return data, labels\n",
    "\n",
    "data, data_gt = dict_to_array(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(512, 217, 204)\n(512, 217)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化，这个归一化的方法有点不一样\n",
    "data = data -float(np.min(data))\n",
    "data = data/np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4386\n",
      "(4386, 5, 5, 204)\n"
     ]
    }
   ],
   "source": [
    "# 原始数据转化为X_data 为 (4205, 5, 5, 204) # 21,445,500; 4386*25=109,650\n",
    "X_data = []\n",
    "step = 5\n",
    "x = range(0, 510, step)\n",
    "y = range(0, 215, step)\n",
    "for i in x:\n",
    "  for j in y:\n",
    "    X_data.append(data[i:i+step, j:j+step])\n",
    "print(len(X_data))\n",
    "# X_data = np.array(X_data)[:4205].astype(np.float32)\n",
    "X_data = np.array(X_data).astype(np.float32)\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 学习使用scipy.stats.mode\n",
    "# #  from scipy.stats import mode\n",
    "# from scipy.stats import mode\n",
    "# a = np.array([[2, 2, 2, 1],\n",
    "#               [1, 2, 2, 2],\n",
    "#               [1, 1, 3, 3]])\n",
    "# print(\"# Print mode(a):\", mode(a))\n",
    "# print(\"# Print mode(a.transpose()):\", mode(a.transpose()))\n",
    "# print(\"# a的每一列中最常见的成员为：{}，分别出现了{}次。\".format(mode(a)[0][0], mode(a)[1][0]))\n",
    "# print(\"# a的第一列中最常见的成员为：{}，出现了{}次。\".format(mode(a)[0][0][0], mode(a)[1][0][0]))\n",
    "# print(\"# a的每一行中最常见的成员为：{}，分别出现了{}次。\".format(mode(a.transpose())[0][0], mode(a.transpose())[1][0]))\n",
    "# print(\"# a中最常见的成员为：{}，出现了{}次。\".format(mode(a.reshape(-1))[0][0], mode(a.reshape(-1))[1][0]))\n",
    "# print(mode(a))\n",
    "# print(mode(a)[0])\n",
    "# print(mode(a)[1])\n",
    "# print(mode(a)[0][0])\n",
    "# print(mode(a)[1][0])\n",
    "# print(mode(a.reshape(-1)))\n",
    "# print(mode(a.reshape(-1))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# data_gt[0:5, 0:5].reshape(25, -1)\n",
    "# mode(data_gt[0:5, 0:5].reshape(25, -1))[0][0][0]   # 输出在这25个像素中出现最多的像素的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4386,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# 这一行的作用是把5*5小方块中出现最多的像素作为这一个小方块中的类别编号，作用可能就是降低数据的容量，加快训练速度！！\n",
    "# 标签数据 Y_data\n",
    "import scipy.stats\n",
    "Y_data = []\n",
    "for i in x:\n",
    "  for j in y:\n",
    "      # 返回传入数组/矩阵中最常出现的成员以及出现的次数。\n",
    "    label = scipy.stats.mode(data_gt[i:i+step, j:j+step].reshape(step*step, 1))[0][0][0]\n",
    "    Y_data.append(label)\n",
    "Y_data = np.array(Y_data)\n",
    "print(Y_data.shape)\n",
    "type(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对比一下用5*5代替1*1的情况下两种标签方式的图像\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "# ax[0].imshow(Y_data.reshape(102, 43), cmap='nipy_spectral')\n",
    "# ax[1].imshow(data_gt, cmap='nipy_spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = Y_data.astype(np.int32)\n",
    "Y_data = Y_data.reshape(len(Y_data), 1)\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "# ax[0].imshow(Y_data.reshape(100, 42), cmap='nipy_spectral')\n",
    "# ax[1].imshow(data_gt, cmap='nipy_spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4386, 5, 5, 204)\n(4386, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_data.shape)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1754, 5, 5, 204), (2632, 5, 5, 204), (1754, 1), (2632, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(train, test, train_label, test_label) = train_test_split(X_data, Y_data, test_size=0.6)\n",
    "train.shape, test.shape, train_label.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSZ = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<RepeatDataset shapes: ((None, 5, 5, 204), (None, 1)), types: (tf.float32, tf.int32)>,\n",
       " <BatchDataset shapes: ((None, 5, 5, 204), (None, 1)), types: (tf.float32, tf.int32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# 创建dataset\n",
    "db = tf.data.Dataset.from_tensor_slices((train,train_label))  # 训练集合标签！\n",
    "db = db.shuffle(4205).batch(BATCHSZ).repeat()\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((test,test_label))\n",
    "db_test = db_test.batch(BATCHSZ)\n",
    "db, db_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('tensorflow2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9ecbc95d31df1b277e5ec566a835865c3a9a253da4266404bdbc6ee7e31406f4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}