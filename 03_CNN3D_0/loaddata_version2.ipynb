{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('tensorflow2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9ecbc95d31df1b277e5ec566a835865c3a9a253da4266404bdbc6ee7e31406f4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 构造用于三维卷积神经网络的数据集\n",
    "- 用周围19个像素的值取预测一个值，貌似太大了\n",
    "- 将得到的数据集储存起来，让卷积模块调用"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('E:\\Eric_HSI\\hyperspectral_datasets')\n",
    "data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))\n",
    "labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))\n",
    "\n",
    "window_size=19\n",
    "input_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(145, 145, 200)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(21025, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# 数据\n",
    "# print(mat.keys())\n",
    "features = data['data']\n",
    "features_shape = features.shape\n",
    "print(features.shape)\n",
    "# 标签\n",
    "labels = labels['groundT']\n",
    "labels = np.reshape(labels, (-1, 1))   # 把标签变为2维， (21025, 1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 (21025, 19, 19, 200) 的数组装数据\n",
    "dataset = np.zeros((labels.shape[0], window_size, window_size, input_size), dtype='float32')\n",
    "\n",
    "# parameter？？\n",
    "parameter_b = np.array([i - window_size // 2 for i in range(window_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(features_shape[0]):\n",
    "    for j in range(features_shape[1]):\n",
    "        index = i * features_shape[1] + j\n",
    "        for p in range(window_size):\n",
    "            for q in range(window_size):\n",
    "                dataset[index][p][q] = \\\n",
    "                    features[(i + parameter_b[p]) % features_shape[0]][(j + parameter_b[q]) % features_shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21025, 1)\n(10249, 1)\n"
     ]
    }
   ],
   "source": [
    "# 删除所有没有标签的像素\n",
    "print(labels.shape)\n",
    "index = np.where(np.reshape(labels, (-1)) == 0)   # 返回坐标tuple(ndarray)\n",
    "labels = np.delete(labels, index, axis=0)\n",
    "print(labels.shape)"
   ]
  },
  {
   "source": [
    "# 中间都在做一些删除拆分的操作"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.unique(labels)   # array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
    "for i in range(len(labels)):\n",
    "    labels[i][0] = np.where(tmp == labels[i][0])[0][0]  # (array([1], dtype=int64),) 第一个[0]索引出元祖中的ndarray，第二[0]索引出ndarray中的int值,处理后，所有的标签值-1 ，因为本来中标签没用0，但是经过Len(labels)，np.where 定位索引位置，又从0开始，所以标签值-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.delete(dataset, index, axis=0)\n",
    "labels = np.reshape(labels, (-1))  # 降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset_shape:  (10249, 200, 19, 19)\ndataset_shape:  (10249, 200, 19, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.swapaxes(1, 3)      # 交换轴\n",
    "print('dataset_shape: ', dataset.shape)\n",
    "\n",
    "# input : 输入，其格式为[batch, in_depth, in_height, in_width, in_channels].可以这样理解，输入batch个 长*宽*高 的图像，添加一个轴channels为1\n",
    "dataset = dataset[:, :, :, :, np.newaxis]     # 添加轴channels\n",
    "print('dataset_shape: ', dataset.shape)\n",
    "\n",
    "# before dataset_shape:  (10249, 200, 19, 19)\n",
    "# after dataset_shape:  (10249, 200, 19, 19, 1)\n",
    "# print(Y.shape)  # (10249,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转化为类别变量\n",
    "classes = 16\n",
    "labels = tf.keras.utils.to_categorical(labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化\n",
    "dataset = dataset.astype('float32')\n",
    "dataset -= np.mean(dataset)\n",
    "dataset /= np.max(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train_new, y_train_new, x_val_new, y_val_new = train_test_split(dataset, labels, test_size=0.8, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2049, 200, 19, 19, 1), (8200, 200, 19, 19, 1), (2049, 16), (8200, 16))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "x_train_new.shape, y_train_new.shape, x_val_new.shape, y_val_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x_train = r\"E:\\Eric_HSI\\excise2\\np_data\\x_train\" + \".npy\"\n",
    "path_x_val = r\"E:\\Eric_HSI\\excise2\\np_data\\x_val\" + \".npy\"\n",
    "path_y_train = r\"E:\\Eric_HSI\\excise2\\np_data\\y_train\" + \".npy\"\n",
    "path_y_val = r\"E:\\Eric_HSI\\excise2\\np_data\\y_val\" + \".npy\"\n",
    "\n",
    "\n",
    "np.save(path_x_train, x_train_new)\n",
    "np.save(path_x_val, x_val_new)\n",
    "np.save(path_y_train, y_train_new)\n",
    "np.save(path_y_val, y_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}