{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import models, Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential, datasets, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        exit(-1)"
   ]
  },
  {
   "source": [
    "# data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "BATCHSZ = 32\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "E:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\data.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\data_label.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\test.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\test_label.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\train.npy\nE:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\\train_label.npy\n"
     ]
    }
   ],
   "source": [
    "data_dir= \"E:\\Eric_HSI\\hyper_data_preprocess\\Salinas_w_size_9_num_200_for_2D\"\n",
    "data_root = glob.glob(data_dir + '/*')\n",
    "for name in glob.glob(data_dir + '/*'):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((3200, 9, 9, 204), (3200,), (50929, 9, 9, 204), (50929,))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train = np.load(data_root[4])\n",
    "train_label = np.load(data_root[5])\n",
    "test = np.load(data_root[2])\n",
    "test_label = np.load(data_root[3])\n",
    "train.shape, train_label.shape, test.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = tf.keras.utils.to_categorical(train_label)\n",
    "test_label = tf.keras.utils.to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 16\n",
    "im_height = 9\n",
    "im_width = 9\n",
    "im_channel = train.shape[3]\n",
    "train_num = train.shape[0]\n",
    "val_num = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据可用的CPU动态设置并行调用的数量， 应用于 num_parallel_calls\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "source": [
    "- prefetch(AUTOTUNE)\n",
    "- 当GPU执行在当前批次执行前向或者后向传播时，我们希望CPU处理下一个批次的数据，以便于数据批次能够迅速被GPU使用。我们希望GPU被完全、时刻用于训练。我们称这种机制为消费者/生产者重叠，消费者是GPU，生产者是CPU。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# dataset顺序：\n",
    "\n",
    "- 创建实例                             from_tensor_slices                       \n",
    "- 重组（较大的buffer_size）             shuffle\n",
    "- 重复                                  repeat\n",
    "- 数据预处理、数据扩增，使用多线程等                  map\n",
    "- 批次化                                batch\n",
    "- 预取数据                             prefectch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = tf.keras.utils.to_categorical(train_label)\n",
    "test_label = tf.keras.utils.to_categorical(test_label)\n",
    "\n",
    "# 根据可用的CPU动态设置并行调用的数量， 应用于 num_parallel_calls\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# load train dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train, train_label))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=train_num).repeat().batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_num).batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "\n",
    "# load test dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((test, test_label))\n",
    "# val_dataset = val_dataset.repeat().batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCHSZ).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 9, 9, 204), (None, 16)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 9, 9, 204), (None, 16)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "train_dataset, val_dataset "
   ]
  },
  {
   "source": [
    "# model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG(feature, im_height=224, im_width=224, class_num=1000):\n",
    "    # tensorflow中的tensor通道排序是NHWC\n",
    "    # change\n",
    "    # input_image = layers.Input(shape=(im_height, im_width, 3), dtype=\"float32\")\n",
    "    input_image = layers.Input(shape=(im_height, im_width, im_channel), dtype=\"float32\")\n",
    "    x = feature(input_image)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    x = layers.Dense(2048, activation='relu')(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    x = layers.Dense(2048, activation='relu')(x)\n",
    "    x = layers.Dense(class_num)(x)\n",
    "    output = layers.Softmax()(x)\n",
    "    model = models.Model(inputs=input_image, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(cfg):\n",
    "    feature_layers = []\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            # change\n",
    "            # feature_layers.append(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "            feature_layers.append(layers.MaxPool2D(pool_size=2, strides=1))\n",
    "        else:\n",
    "            conv2d = layers.Conv2D(v, kernel_size=3, padding=\"SAME\", activation=\"relu\")\n",
    "            feature_layers.append(conv2d)\n",
    "    return Sequential(feature_layers, name=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络配置列表\n",
    "cfgs = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(model_name=\"vgg16\", im_height=224, im_width=224, class_num=1000):\n",
    "    try:\n",
    "        cfg = cfgs[model_name]\n",
    "    except:\n",
    "        print(\"Warning: model number {} not in cfgs dict!\".format(model_name))\n",
    "        exit(-1)\n",
    "    model = VGG(features(cfg), im_height=im_height, im_width=im_width, class_num=class_num)\n",
    "    return model"
   ]
  },
  {
   "source": [
    "# train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "model = vgg(model_name=\"vgg16\", im_height=im_height, im_width=im_width, class_num=class_num)\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "# using keras low level api for training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create direction for saving weights\n",
    "if not os.path.exists(\"save_weights_lowAPI\"):\n",
    "    os.makedirs(\"save_weights_lowAPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # dropout 层需要设置 trianing \n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # dropout 层需要设置 trianing \n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_loss = float('inf')\n",
    "train_step_num = train_num // BATCHSZ\n",
    "val_step_num = val_num // BATCHSZ\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss.reset_states()        # clear history info\n",
    "    train_accuracy.reset_states()    # clear history info\n",
    "    test_loss.reset_states()         # clear history info\n",
    "    test_accuracy.reset_states()     # clear history info\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    for index, (images, labels) in enumerate(train_dataset):\n",
    "        train_step(images, labels)\n",
    "        if index+1 == train_step_num:\n",
    "            break\n",
    "    print(time.perf_counter()-t1)\n",
    "\n",
    "    for index, (images, labels) in enumerate(val_dataset):\n",
    "        test_step(images, labels)\n",
    "        if index+1 == val_step_num:\n",
    "            break\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))\n",
    "    if test_loss.result() < best_test_loss:\n",
    "        model.save_weights(\"./save_weights_lowAPI/myVGG.ckpt\".format(epoch), save_format='tf')"
   ]
  },
  {
   "source": [
    "# using keras high level api for training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = tf.keras.utils.to_categorical(train_label)\n",
    "test_label = tf.keras.utils.to_categorical(test_label)\n",
    "\n",
    "# 根据可用的CPU动态设置并行调用的数量， 应用于 num_parallel_calls\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# load train dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train, train_label))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_num).repeat().batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=train_num).batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "\n",
    "# load test dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((test, test_label))\n",
    "val_dataset = val_dataset.repeat().batch(BATCHSZ).prefetch(AUTOTUNE)\n",
    "# val_dataset = val_dataset.batch(BATCHSZ).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 9, 9, 204)]       0         \n_________________________________________________________________\nfeature (Sequential)         (None, 4, 4, 512)         9520768   \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 2048)              16779264  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 2048)              4196352   \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                32784     \n_________________________________________________________________\nsoftmax (Softmax)            (None, 16)                0         \n=================================================================\nTotal params: 30,529,168\nTrainable params: 30,529,168\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = vgg(model_name=\"vgg13\", im_height=im_height, im_width=im_width, class_num=class_num)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create direction for saving weights\n",
    "if not os.path.exists(\"save_weights\"):\n",
    "    os.makedirs(\"save_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   1/1591 [..............................] - ETA: 0s - loss: 2.7724 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0160s). Check your callbacks.\n",
      "1591/1591 [==============================] - 38s 24ms/step - loss: 2.8399 - accuracy: 0.0349 - val_loss: 2.8121 - val_accuracy: 0.0625\n",
      "Epoch 2/100\n",
      "   1/1591 [..............................] - ETA: 0s - loss: 2.8746 - accuracy: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 159100 batches). You may need to use the repeat() function when building your dataset.\n",
      "   1/1591 [..............................] - 1s 884ms/step - loss: 2.8746 - accuracy: 0.0000e+00 - val_loss: 2.8121 - val_accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "            #   from_logits=False 如果没有进行 softmax 处理，这里执行 True\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "# change + \n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=3, min_lr=0.000001)\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./save_weights/myVGG.h5',\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss')]\n",
    "\n",
    "# tensorflow2.1 recommend to using fit\n",
    "# history = model.fit(train_dataset,\n",
    "#                     steps_per_epoch=train_num // BATCHSZ,\n",
    "#                     epochs=EPOCHS,\n",
    "#                     validation_data=val_dataset,\n",
    "#                     validation_steps=val_num // BATCHSZ,\n",
    "#                     callbacks=[callbacks, reduce_lr])\n",
    "history = model.fit(val_dataset,\n",
    "                    steps_per_epoch=val_num // BATCHSZ,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=train_dataset,\n",
    "                    validation_steps=train_num // BATCHSZ,\n",
    "                    callbacks=[callbacks, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}